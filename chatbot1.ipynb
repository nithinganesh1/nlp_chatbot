{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c31b2f98-1400-40ca-a2e2-58be555fc90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk #to process natural language\n",
    "import numpy as np\n",
    "import random # to generte random responses to feel less repetitive\n",
    "import string # to do string manipulations, because sometimes we need to remove punctuations ,need to convert it in lowercase etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1791962-f099-415f-a95c-2a8771a998ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('Machine learning.txt', 'r', errors='ignore')\n",
    "raw = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1914670-7a5c-40f3-a5c4-2fce1605e8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['machine  learning is a rapidly evolving field within artificial intelligence (ai) that focuses on the development of algorithms and statistical models that enable computers to learn from and make predictions or decisions based on data.', 'unlike traditional programming where explicit instructions are given for each task, machine learning allows systems to learn patterns and relationships within data, and to improve their performance over time as they are exposed to more data.', 'this capability is grounded in the idea that systems can automatically improve their performance without human intervention through experience.', 'at its core, machine learning is divided into several categories, with the primary ones being supervised learning, unsupervised learning, and reinforcement learning.', 'each of these categories approaches the task of learning from data in a unique way, depending on the nature of the data and the desired outcome.']\n",
      "['machine', 'learning', 'is', 'a', 'rapidly']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/nithin/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/nithin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/nithin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.data.path.append('/home/nithin/nltk_data')  # Add your nltk_data path\n",
    "nltk.download('punkt_tab')\n",
    "raw=raw.lower()# convert all strings to lowercase\n",
    "nltk.download('punkt')# Punkt is a pre-trained model that helps in sentence tokenization, i.e., splitting a text into sentences\n",
    "nltk.download('wordnet')#WordNet is a large database of English words that groups words into sets of synonyms \n",
    "sentence_tokens = nltk.sent_tokenize(raw)\n",
    "word_tokens = nltk.word_tokenize(raw)\n",
    "print(sentence_tokens[:5])\n",
    "print(word_tokens[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b7105e7-4e58-4a7f-aca6-92d074ce8ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the text by removing punctuation and reducing words to their base or root form (lemmatization)\n",
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation) ##This dictionary will be used to remove punctuation from the text.\n",
    "\n",
    "def lem_tokens(tokens): #takes a list of tokens (words) as input and returns a list of lemmatized tokens.\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "\n",
    "def lem_normalize(text):#This function, lem_normalize, normalizes the input text by performing  translate(),lower(), tokenize()\n",
    "    return lem_tokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n",
    "\n",
    "# translate() used to modify a string by replacing characters based on a specified translation table\n",
    "#text.lower() converts all characters in the text to lowercase, ensuring uniformity.\n",
    "#translate(remove_punct_dict) removes any punctuation from the text using the remove_punct_dict created earlier.\n",
    "#nltk.word_tokenize() splits the cleaned text into individual words (tokens).\n",
    "#lem_tokens() is then called to lemmatize each token in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c603ec47-5fb1-442b-9a2e-c84c75e26453",
   "metadata": {},
   "outputs": [],
   "source": [
    "GREETING_INPUTS = ('hello', 'hi', 'greetings', 'sup', 'what\\'s up', 'hey',)\n",
    "GREETING_RESPONSES = ['hi', 'hey', '*nods*', 'hi there', 'hello', 'I am glad! You are talking to me']\n",
    "\n",
    "def greeting(sentence):\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51665a04-da97-46d0-a42d-45d6f9100c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generates a response to a user's input based on the similarity between the user's query and the chatbot's available data.\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer #TF-IDF is a statistical measure used to evaluate the importance of a \n",
    "#word in a document relative to a collection of documents (corpus). TF-IDF allows the model to focus on the most important \n",
    "#words when comparing the user input to the available data.\n",
    "from sklearn.metrics.pairwise import cosine_similarity #Cosine similarity is widely used in text processing to measure\n",
    "# the similarity between two documents (or sentences) represented as vectors\n",
    "\n",
    "\n",
    "def response(user_response):\n",
    "    robo_response = ''\n",
    "    # Temporarily add user_response for similarity calculation\n",
    "    temp_tokens = sentence_tokens + [user_response]\n",
    "\n",
    "    vectorizer = TfidfVectorizer(tokenizer=lem_normalize, stop_words='english')\n",
    "    tfidf = vectorizer.fit_transform(temp_tokens)  # Use the temporary token list\n",
    "\n",
    "    values = cosine_similarity(tfidf[-1], tfidf[:-1])  # Compare with all except the last one (user response)\n",
    "    idx = values.argsort()[0][-1]  # Find the most similar sentence\n",
    "    flat = values.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-1]  # Get the highest similarity score\n",
    "\n",
    "    if req_tfidf == 0:\n",
    "        robo_response = '{} Sorry, I don\\'t understand you'.format(robo_response)\n",
    "    else:\n",
    "        robo_response = robo_response + sentence_tokens[idx]\n",
    "    return robo_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9665841-6bf6-44ad-b455-25afecd70bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyttsx3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.91)\n",
      "Requirement already satisfied: comtypes in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyttsx3) (1.4.6)\n",
      "Requirement already satisfied: pypiwin32 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyttsx3) (305.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecccf2b4-4eef-49d7-ab8c-97d272b0d4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "engine = pyttsx3.init()\n",
    "# Set the rate (speed) of speech\n",
    "engine.setProperty('rate', 150)  # 150 words per minute\n",
    "\n",
    "# Set the volume (0.0 to 1.0)\n",
    "engine.setProperty('volume', 0.9)  # 90% volume\n",
    "engine.say(\"Hello, how can I assist you today?\")\n",
    "engine.runAndWait()#generates a response to a user's input based on the similarity between the user's query and the chatbot's available data.\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer #TF-IDF is a statistical measure used to evaluate the importance of a \n",
    "#word in a document relative to a collection of documents (corpus). TF-IDF allows the model to focus on the most important \n",
    "#words when comparing the user input to the available data.\n",
    "from sklearn.metrics.pairwise import cosine_similarity #Cosine similarity is widely used in text processing to measure\n",
    "# the similarity between two documents (or sentences) represented as vectors\n",
    "\n",
    "\n",
    "def response(user_response):\n",
    "    robo_response = ''\n",
    "    # Temporarily add user_response for similarity calculation\n",
    "    temp_tokens = sentence_tokens + [user_response]\n",
    "\n",
    "    vectorizer = TfidfVectorizer(tokenizer=lem_normalize, stop_words='english')\n",
    "    tfidf = vectorizer.fit_transform(temp_tokens)  # Use the temporary token list\n",
    "\n",
    "    values = cosine_similarity(tfidf[-1], tfidf[:-1])  # Compare with all except the last one (user response)\n",
    "    idx = values.argsort()[0][-1]  # Find the most similar sentence\n",
    "    flat = values.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-1]  # Get the highest similarity score\n",
    "\n",
    "    if req_tfidf == 0:\n",
    "        robo_response = '{} Sorry, I don\\'t understand you'.format(robo_response)\n",
    "    else:\n",
    "        robo_response = robo_response + sentence_tokens[idx]\n",
    "    return robo_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cd7f762-8d18-4d90-ad1a-1511a22db8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOT: My name is Robo, I will answer your questions about Machine Learning. If you want to exit, type Bye\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  do you know about ml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBO:  Sorry, I don't understand you\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  do you know about machine learing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBO: supervised learning is perhaps the most common type of machine learning.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  do you know about ai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBO: machine  learning is a rapidly evolving field within artificial intelligence (ai) that focuses on the development of algorithms and statistical models that enable computers to learn from and make predictions or decisions based on data.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  hii, can you  tell me about q learing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBO:  Sorry, I don't understand you\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  hii, do you know about dql\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBO:  Sorry, I don't understand you\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  hii, do you know about reenforcement learing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBO:  Sorry, I don't understand you\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  hii, do you know about reinforcement learning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBO: at its core, machine learning is divided into several categories, with the primary ones being supervised learning, unsupervised learning, and reinforcement learning.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOT: bye!\n"
     ]
    }
   ],
   "source": [
    "flag = True\n",
    "print('BOT: My name is Robo, I will answer your questions about Machine Learning. If you want to exit, type Bye')\n",
    "\n",
    "interactions = [\n",
    "    'hi',\n",
    "    'what is Machine Learning?',\n",
    "    'What are the different types of Machine Learning algorithms?',\n",
    "    'What is the difference between supervised and unsupervised learning',\n",
    "    'What is the difference between classification and regression?',\n",
    "    'machine learning algorithms?'\n",
    "    'sounds awesome',\n",
    "    'bye',\n",
    "]\n",
    "while flag:\n",
    "    user_response = input(\"User: \")\n",
    "    user_response = user_response.lower()\n",
    "    if user_response != 'bye':\n",
    "        if user_response == 'thanks' or user_response == 'thank you':\n",
    "            flag = False\n",
    "            print('BOT: You are welcome...')\n",
    "        elif greeting(user_response) is not None:\n",
    "            print('ROBO: {}'.format(greeting(user_response)))\n",
    "            engine.say(format(greeting(user_response)))\n",
    "            engine.runAndWait()\n",
    "        else:\n",
    "            print('ROBO: ', end='')\n",
    "            print(response(user_response))\n",
    "            engine.say(format(response(user_response)))\n",
    "            engine.runAndWait()\n",
    "\n",
    "    else:\n",
    "        flag = False\n",
    "        print('BOT: bye!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb8b46b-54f0-4dd8-b4dd-1f596b445d79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
